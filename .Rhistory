library(caret)
install.packages("caret")
library(caret)
library(kernlab)
install.packages("kernlab")
library(kernlab)
data("spam")
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
dim(testing)
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("reshape2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library(caret)
data("faithful")
set.seed(333)
inTrain <-createDataPartition(y=faithful$waiting,p=0.5,list=FALSE)
trainFaith <- faithful[inTrain,]
testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting, trainFaith$eruptions, xlab = "Waiting", ylab = "Duration")
lm1 <- lm(eruptions ~ waiting, data = trainFaith)
summary(lm1)
lines(trainFaith$waiting, lm1$fitted)
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
plot(testFaith$waiting, testFaith$eruptions, xlab = "Waiting", ylab = "Duration")
lines(testFaith$waiting, predict(lm1, newdata=testFAith)
)
lines(testFaith$waiting, predict(lm1, newdata=testFaith))
library(ISLR)
install.packages(ISLR)
install.packages("ISLR")
library(ISLR)
library(ggplot2)
data("Wage")
Wage <- subset(Wage, select = -c(logwage))
summary(Wage)
inTrain <- createDataPartition(Wage, p=0.7, list=FALSE)
inTrain <- createDataPartition(Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
qplot(age,wage,colour=jobclass,data=training)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
install.packages("Hmisc")
data(concrete)
data(cement)
library(AppliedPredictiveModeling)
data("concrete")
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[ -inTrain,]
help(cut2)
hist(mixtures$Superplasticizer)
summary(mixtures)
cutCement <- cut2(mixtures$CompressiveStrength, g=8)
library(Hmisc)
cutCement <- cut2(mixtures$CompressiveStrength, g=8)
cutCement
cutCement <- cut2(mixtures$CompressiveStrength, g=4)
summary(cutCement)
library(AppliedPredictiveModeling)
data("segmentationOriginal")
library(caret)
head(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Case ~ ., method="rpart", data=training)
modFit <- train(Case ~ ., method="rpart", data=training)
library(rpart)
modFit <- train(Case ~ ., method="rpart", data=training)
library(e1071)
install.packages("e1071")
library(e1071)
modFit <- train(Case ~ ., method="rpart", data=training)
print(modFit$finalModel)
install.packages('rattle')
library(rattle)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rpart.plot)
install.packages(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
modFit <- train(Class ~ ., method="rpart", data=training)
print(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
set.seed(125)
modFit <- train(Class ~ ., method="rpart", data=training)
print(modFit$finalModel)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data("SAheart")
set.seed(8484)
train = sample(1:dim(SAheart)[1], size=dim(SAheart)[1]/2,replace = F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
set.seed(13234)
modelFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", family = "binomial", data = trainSA)
trainingpredict <- predict(modelFit, trainSA)
testingpredict <- predict(modelFit, testSA)
missClass(trainSA$chd, trainingpredict)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, trainingpredict)
missClass(testSA$chd, testingpredict)
data("vowel.test")
data("vowel.train")
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
install.packages("randomForest")
library(randomForest)
modelFit <- randomForest(y ~ ., data = vowel.train, importance=FALSE)
order(varImp(modelFit), decreasing = TRUE)
install.packages("pgmm")
library(pgmm)
data("olive")
olive = olive[,-1]
str(olive)
modelFit <- train(Area ~., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modelFit, newdata)
modelFit$finalModel
fancyRpartPlot(modelFit$finalModel)
library(ElemStatLearn)
data("vowel.train")
data("vowel.test")
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
modFitrf <- train(y ~ ., data=vowel.test, method="rf", prox=TRUE)
modFitrf <- train(y ~ ., data=vowel.train, method="rf")
modFitgbm <- train(y ~ ., data=vowel.train, method="gbm")
predict_rf <- predict(modFitrf, vowel.test)
predict_gbm <- predict(modFitgbm, vowel.test)
confusionMatrix(predict_rf,vowel.test$y)$overall[1]
confusionMatrix(predict_gbm,vowel.test$y)$overall[1]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod_rf <- train(diagnosis ~ .,data=training, method="rf")
mod_gbm <- train(diagnosis ~ .,data=training, method="gbm")
mod_lda <- train(diagnosis ~ .,data=training, method="lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis=testing$diagnosis)
combFit <- train(diagnosis ~ ., method="rf", data=predDF)
combPred <- predict(combFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
confusionMatrix(predDF, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
set.seed(3523)
data("concrete")
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod
mod_lasso <- train(CompressiveStrength ~ ., data=training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate) # For year() function below
install.packages("lubridate")
library(lubridate) # For year() function below
#---------------End of program-----------------
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
---
)
oddcount <- function (x){
k <- 0 # assign 0 to k
for (n in x) {
if (n %% 2 == 1) k <- k+1 # %% is the modulo operator
}
}
oddcount <- function (x){
k <- 0 # assign 0 to k
for (n in x) {
if (n %% 2 == 1) k <- k+1 # %% is the modulo operator
}
return(k)
}
oddcount(c(1,3,5))
oddcount(c(1,2,3,7,9))
38 %% 7
oddcount(c(1,2,3,4,5,6,7,8,9,0))
f <- function(x) return(x+y)
y <- 3
f(5)
g <- function(x, y=2, z=T) {...}
g(12,z=FALSE)
g <- function(x, y=2, z=T) { ... }
g(12,z=FALSE)
x <- 8
x
x <- c(5,12,13)
x
length(x)
mode(x)
y <- "abc"
y
length(y)
mode(y)
z <- c("abc", "28 29")
z
length(z)
mode(z)
u <- paste("abc", "de", "f")
u
v <- strsplit(u," ")
v
m <- rbind(c(1,4),c(2,2))
m
m %*% c(1,1)
m[1,2]
m[2,2]
m[1,]
m[,2]
x <- list(u=2, v="abc")
x
x$u
x$v
hist(Nile)
hn <- hist(Nile)
print(hn)
hn
str(hn)
d <- data.frame(list(kids=c("Jack","Jill"), ages=c(12,10)))
d
d$ages
d$kids
summary(hn)
summary(d)
example("seq")
example("persp")
getwd()
setwd("~/Documents/Data Science_Coursera/Project")
library(shiny)
runApp()
runApp()
runApp()
runApp()
